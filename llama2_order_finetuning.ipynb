{"cells":[{"cell_type":"markdown","id":"28e4c4d1-a73f-437b-a1bd-c2cc3874924a","metadata":{"id":"28e4c4d1-a73f-437b-a1bd-c2cc3874924a"},"source":["# llama2-food-order-understanding\n","\n","1. llama-2-7b-chat-hf 를 주문 문장 이해에 미세 튜닝\n","\n","- food-order-understanding-small-3200.json (학습)\n","- food-order-understanding-small-800.json (검증)\n","\n","\n","종속적인 필요 내용\n","- huggingface 계정 설정 및 llama-2 사용 승인\n","- 로깅을 위한 wandb"]},{"cell_type":"code","source":["pip install transformers peft accelerate optimum bitsandbytes trl wandb"],"metadata":{"id":"nDZe_wqKU6J3"},"id":"nDZe_wqKU6J3","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"51eb00d7-2928-41ad-9ae9-7f0da7d64d6d","metadata":{"id":"51eb00d7-2928-41ad-9ae9-7f0da7d64d6d"},"outputs":[],"source":["import os\n","from dataclasses import dataclass, field\n","from typing import Optional\n","import re\n","\n","import torch\n","import tyro\n","from accelerate import Accelerator\n","from datasets import load_dataset, Dataset\n","from peft import AutoPeftModelForCausalLM, LoraConfig\n","from tqdm import tqdm\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n",")\n","\n","from trl import SFTTrainer\n","\n","from trl.trainer import ConstantLengthDataset"]},{"cell_type":"code","source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"],"metadata":{"id":"tX7gYxZaVhYL"},"id":"tX7gYxZaVhYL","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["드라이브 마운트 후 파일 업로드\n","- food-order-understanding-small-3200.json\n","- food-order-understanding-small-800.json"],"metadata":{"id":"FuKA5uZihmdh"},"id":"FuKA5uZihmdh"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"id":"4DF9D2SXVpHP"},"id":"4DF9D2SXVpHP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# /gdrive/MyDrive/Lectures/2023/nlp/food-order-understanding-small-3200.json\n","# /gdrive/MyDrive/Lectures/2023/nlp/food-order-understanding-small-800.json"],"metadata":{"id":"VFgITUI8WjKe"},"id":"VFgITUI8WjKe","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"036eece3-5f89-4fec-b0cd-268478b5e83d","metadata":{"id":"036eece3-5f89-4fec-b0cd-268478b5e83d"},"source":["# 매개 변수 설정"]},{"cell_type":"code","execution_count":null,"id":"e03d01b5-eaeb-4626-9dc5-47c3691e7fcf","metadata":{"id":"e03d01b5-eaeb-4626-9dc5-47c3691e7fcf"},"outputs":[],"source":["@dataclass\n","class ScriptArguments:\n","    cache_dir: Optional[str] = field(\n","        default=None, metadata={\"help\": \"the cache dir\"}\n","    )\n","    model_name: Optional[str] = field(\n","        default=\"meta-llama/Llama-2-7b-chat-hf\", metadata={\"help\": \"the model name\"}\n","    )\n","\n","    dataset_name: Optional[str] = field(\n","        default=None,\n","        metadata={\"help\": \"the dataset name\"},\n","    )\n","    seq_length: Optional[int] = field(\n","        default=1024, metadata={\"help\": \"the sequence length\"}\n","    )\n","    num_workers: Optional[int] = field(\n","        default=8, metadata={\"help\": \"the number of workers\"}\n","    )\n","    training_args: TrainingArguments = field(\n","        default_factory=lambda: TrainingArguments(\n","            output_dir=\"./results\",\n","            # max_steps=500,\n","            logging_steps=20,\n","            # save_steps=10,\n","            per_device_train_batch_size=1,\n","            per_device_eval_batch_size=1,\n","            gradient_accumulation_steps=2,\n","            gradient_checkpointing=False,\n","            group_by_length=False,\n","            learning_rate=1e-4,\n","            lr_scheduler_type=\"cosine\",\n","            # warmup_steps=100,\n","            warmup_ratio=0.03,\n","            max_grad_norm=0.3,\n","            weight_decay=0.05,\n","            save_total_limit=20,\n","            save_strategy=\"epoch\",\n","            num_train_epochs=1,\n","            optim=\"paged_adamw_32bit\",\n","            fp16=True,\n","            remove_unused_columns=False,\n","            report_to=\"wandb\",\n","        )\n","    )\n","\n","    packing: Optional[bool] = field(\n","        default=True, metadata={\"help\": \"whether to use packing for SFTTrainer\"}\n","    )\n","\n","    peft_config: LoraConfig = field(\n","        default_factory=lambda: LoraConfig(\n","            r=8,\n","            lora_alpha=16,\n","            lora_dropout=0.05,\n","            target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"down_proj\", \"up_proj\", \"gate_proj\"],\n","            bias=\"none\",\n","            task_type=\"CAUSAL_LM\",\n","        )\n","    )\n","\n","    merge_with_final_checkpoint: Optional[bool] = field(\n","        default=False, metadata={\"help\": \"Do only merge with final checkpoint\"}\n","    )"]},{"cell_type":"markdown","id":"b0b34850-006c-4c87-a7d5-27c6c871e7de","metadata":{"id":"b0b34850-006c-4c87-a7d5-27c6c871e7de"},"source":["# 유틸리티"]},{"cell_type":"code","execution_count":null,"id":"8224d213-8766-4b40-899e-1a1b8d164365","metadata":{"id":"8224d213-8766-4b40-899e-1a1b8d164365"},"outputs":[],"source":["def chars_token_ratio(dataset, tokenizer, nb_examples=400):\n","    \"\"\"\n","    Estimate the average number of characters per token in the dataset.\n","    \"\"\"\n","    total_characters, total_tokens = 0, 0\n","    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n","        text = prepare_sample_text(example)\n","        total_characters += len(text)\n","        if tokenizer.is_fast:\n","            total_tokens += len(tokenizer(text).tokens())\n","        else:\n","            total_tokens += len(tokenizer.tokenize(text))\n","\n","    return total_characters / total_tokens\n","\n","\n","def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"markdown","id":"58085944-b951-4c9b-bdeb-0ccc60c2a3b3","metadata":{"id":"58085944-b951-4c9b-bdeb-0ccc60c2a3b3"},"source":["# 데이터 로딩"]},{"cell_type":"code","execution_count":null,"id":"b49c3470-480e-4ff2-b2c5-fcf1d3a13fba","metadata":{"id":"b49c3470-480e-4ff2-b2c5-fcf1d3a13fba"},"outputs":[],"source":["def prepare_sample_text(example):\n","    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n","\n","    prompt_template = \"\"\"###System;{System}\n","    ###User;{User}\n","    ###Midm;{Midm}\"\"\"\n","\n","    default_system_msg = (\n","        \"너는 먼저 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 이로부터 주문을 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\"\n","    )\n","\n","    text = (\n","        prompt_template.format(System=default_system_msg, User=example[\"input\"],Midm=example[\"output\"])\n","    )\n","\n","    return text"]},{"cell_type":"code","execution_count":null,"id":"5d9abfb4-339d-414b-855b-ced51631b752","metadata":{"id":"5d9abfb4-339d-414b-855b-ced51631b752"},"outputs":[],"source":["def create_datasets(tokenizer, args):\n","    train_data = Dataset.from_json(args.dataset_name)\n","\n","    chars_per_token = chars_token_ratio(train_data, tokenizer)\n","    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n","\n","    train_dataset = ConstantLengthDataset(\n","        tokenizer,\n","        train_data,\n","        formatting_func=prepare_sample_text,\n","        infinite=True,\n","        seq_length=args.seq_length,\n","        chars_per_token=chars_per_token,\n","    )\n","    return train_dataset"]},{"cell_type":"markdown","id":"2e7ef79d-a354-4c80-9435-c130ffed9e32","metadata":{"id":"2e7ef79d-a354-4c80-9435-c130ffed9e32"},"source":["# 미세 튜닝용 모델 로딩"]},{"cell_type":"code","execution_count":null,"id":"bf4c65e0-5ffa-4a20-9e78-6c1f030572ff","metadata":{"id":"bf4c65e0-5ffa-4a20-9e78-6c1f030572ff"},"outputs":[],"source":["script_args = ScriptArguments(\n","    num_workers=2,\n","    seq_length=512,\n","    dataset_name='/gdrive/MyDrive/Lectures/2023/nlp/food-order-understanding-small-3200.json',\n","    model_name='meta-llama/Llama-2-7b-chat-hf',\n","    )"]},{"cell_type":"code","execution_count":null,"id":"372c64be-8fc0-4cc8-bda8-92ecf3632cc3","metadata":{"id":"372c64be-8fc0-4cc8-bda8-92ecf3632cc3"},"outputs":[],"source":["script_args.training_args.logging_steps = 100\n","# script_args.training_args.max_steps = 100\n","script_args.training_args.output_dir = '/gdrive/MyDrive/Lectures/2023/nlp/lora-llama-2-7b-food-order-understanding'\n","script_args.training_args.run_name = 'llama-2-7b-food-order-understanding'"]},{"cell_type":"code","execution_count":null,"id":"bac62c01-21ef-491e-a686-cf4988186c58","metadata":{"tags":[],"id":"bac62c01-21ef-491e-a686-cf4988186c58"},"outputs":[],"source":["print(script_args)"]},{"cell_type":"code","execution_count":null,"id":"1ff1422e-184d-4438-b033-40ae8bdaa5fd","metadata":{"id":"1ff1422e-184d-4438-b033-40ae8bdaa5fd"},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n",")"]},{"cell_type":"code","execution_count":null,"id":"15c8425e-bb0b-40c5-bfe8-385bac699b9d","metadata":{"tags":[],"id":"15c8425e-bb0b-40c5-bfe8-385bac699b9d"},"outputs":[],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    script_args.model_name,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",  # {\"\": Accelerator().local_process_index},\n","    trust_remote_code=True,\n","    use_auth_token=True,\n","    cache_dir=script_args.cache_dir,\n",")\n","base_model.config.use_cache = False"]},{"cell_type":"code","source":["base_model"],"metadata":{"id":"E9D239NqbDba"},"id":"E9D239NqbDba","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d37b485f-4fd3-404f-ab02-2bf3e93b3fc2","metadata":{"tags":[],"id":"d37b485f-4fd3-404f-ab02-2bf3e93b3fc2"},"outputs":[],"source":["peft_config = script_args.peft_config"]},{"cell_type":"code","execution_count":null,"id":"4420fcc4-2bac-413d-b7aa-89455c512419","metadata":{"id":"4420fcc4-2bac-413d-b7aa-89455c512419"},"outputs":[],"source":["peft_config"]},{"cell_type":"code","execution_count":null,"id":"f47f9584-3988-46b8-a062-29dcde75a0e2","metadata":{"id":"f47f9584-3988-46b8-a062-29dcde75a0e2"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    script_args.model_name,\n","    trust_remote_code=True,\n","    cache_dir=script_args.cache_dir,\n",")\n","\n","if getattr(tokenizer, \"pad_token\", None) is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n","\n","base_model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"code","execution_count":null,"id":"abd17c83-ab8d-44cb-b69b-fc0936c2cec5","metadata":{"id":"abd17c83-ab8d-44cb-b69b-fc0936c2cec5"},"outputs":[],"source":["training_args = script_args.training_args"]},{"cell_type":"code","execution_count":null,"id":"62e8139f-5179-4c75-84a7-0c818ab0a35a","metadata":{"tags":[],"id":"62e8139f-5179-4c75-84a7-0c818ab0a35a"},"outputs":[],"source":["train_dataset = create_datasets(tokenizer, script_args)"]},{"cell_type":"code","execution_count":null,"id":"000314e9-f10b-4685-8da6-0511494a9eb4","metadata":{"id":"000314e9-f10b-4685-8da6-0511494a9eb4"},"outputs":[],"source":["len(train_dataset)"]},{"cell_type":"code","execution_count":null,"id":"4ba80a64-0ec7-4b29-ac95-7b3d34549f17","metadata":{"id":"4ba80a64-0ec7-4b29-ac95-7b3d34549f17"},"outputs":[],"source":["trainer = SFTTrainer(\n","    model=base_model,\n","    train_dataset=train_dataset,\n","    eval_dataset=None,\n","    peft_config=peft_config,\n","    packing=script_args.packing,\n","    max_seq_length=script_args.seq_length,\n","    tokenizer=tokenizer,\n","    args=training_args,\n",")"]},{"cell_type":"code","source":["base_model"],"metadata":{"id":"gw9xbeUgbZEo"},"id":"gw9xbeUgbZEo","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"edb204be-ec15-4800-af49-6cfbad2f7f9a","metadata":{"id":"edb204be-ec15-4800-af49-6cfbad2f7f9a"},"outputs":[],"source":["print_trainable_parameters(base_model)"]},{"cell_type":"markdown","source":["구글 코랩 T-4 GPU: 1:37:34 예상시간\n","- 총 1,600 스텝 필요\n","- 하지만 이보다 일찍 종료됨 약 900번 미만 스텝에서 종료됨\n","\n","시퀀스 길이 512의 경우\n","- 14.4 G / 15.0 G 사용\n","- 메모리 오버플로우 발생시 512보다 줄일 것"],"metadata":{"id":"76sRe172fGlm"},"id":"76sRe172fGlm"},{"cell_type":"code","execution_count":null,"id":"14019fa9-0c6f-4729-ac99-0d407af375b8","metadata":{"id":"14019fa9-0c6f-4729-ac99-0d407af375b8"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","source":["script_args.training_args.output_dir"],"metadata":{"id":"3Y4FQSyRghQt"},"id":"3Y4FQSyRghQt","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"49f05450-da2a-4edd-9db2-63836a0ec73a","metadata":{"id":"49f05450-da2a-4edd-9db2-63836a0ec73a"},"outputs":[],"source":["trainer.save_model(script_args.training_args.output_dir)"]},{"cell_type":"markdown","id":"652f307e-e1d7-43ae-b083-dba2d94c2296","metadata":{"id":"652f307e-e1d7-43ae-b083-dba2d94c2296"},"source":["# 추론 테스트"]},{"cell_type":"code","execution_count":null,"id":"ea8a1fea-7499-4386-9dea-0509110f61af","metadata":{"id":"ea8a1fea-7499-4386-9dea-0509110f61af"},"outputs":[],"source":["from transformers import pipeline, TextStreamer"]},{"cell_type":"code","execution_count":null,"id":"52626888-1f6e-46b6-a8dd-836622149ff5","metadata":{"id":"52626888-1f6e-46b6-a8dd-836622149ff5"},"outputs":[],"source":["instruction_prompt_template = \"\"\"###System;다음은 매장에서 고객이 음식을 주문하는 주문 문장이다. 이를 분석하여 음식명, 옵션명, 수량을 추출하여 고객의 의도를 이해하고자 한다.\n","분석 결과를 완성해주기 바란다.\n","\n","### 주문 문장: {0} ### 분석 결과:\n","\"\"\"\n","\n","prompt_template = \"\"\"###System;{System}\n","###User;{User}\n","###Midm;\"\"\"\n","\n","default_system_msg = (\n","    \"너는 먼저 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 이로부터 주문을 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\"\n",")"]},{"cell_type":"code","execution_count":null,"id":"46e844fa-8f63-4359-a4fb-df66e8171796","metadata":{"id":"46e844fa-8f63-4359-a4fb-df66e8171796"},"outputs":[],"source":["evaluation_queries = [\n","    \"오늘은 비가오니깐 이거 먹자. 삼선짬뽕 곱배기 하나하구요, 사천 탕수육 중짜 한그릇 주세요.\",\n","    \"아이스아메리카노 톨사이즈 한잔 하고요. 딸기스무디 한잔 주세요. 또, 콜드브루라떼 하나요.\",\n","    \"참이슬 한병, 코카콜라 1.5리터 한병, 테슬라 한병이요.\",\n","    \"꼬막무침 1인분하고요, 닭도리탕 중자 주세요. 그리고 소주도 한병 주세요.\",\n","    \"김치찌개 3인분하고요, 계란말이 주세요.\",\n","    \"불고기버거세트 1개하고요 감자튀김 추가해주세요.\",\n","    \"불닭볶음면 1개랑 사리곰탕면 2개 주세요.\",\n","    \"카페라떼 아이스 샷추가 한잔하구요. 스콘 하나 주세요\",\n","    \"여기요 춘천닭갈비 4인분하고요. 라면사리 추가하겠습니다. 콜라 300ml 두캔주세요.\",\n","    \"있잖아요 조랭이떡국 3인분하고요. 떡만두 한세트 주세요.\",\n","    \"깐풍탕수 2인분 하고요 콜라 1.5리터 한병이요.\",\n","]"]},{"cell_type":"code","execution_count":null,"id":"1919cf1f-482e-4185-9d06-e3cea1918416","metadata":{"id":"1919cf1f-482e-4185-9d06-e3cea1918416"},"outputs":[],"source":["def wrapper_generate(model, input_prompt):\n","    data = tokenizer(input_prompt, return_tensors=\"pt\")\n","    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","    input_ids = data.input_ids[..., :-1]\n","    with torch.no_grad():\n","        pred = model.generate(\n","            input_ids=input_ids.cuda(),\n","            streamer=streamer,\n","            use_cache=True,\n","            max_new_tokens=float('inf'),\n","            temperature=0.5\n","        )\n","    decoded_text = tokenizer.batch_decode(pred, skip_special_tokens=True)\n","    return (decoded_text[0][len(input_prompt):])"]},{"cell_type":"code","execution_count":null,"id":"eaac1f6f-c823-4488-8edb-2f931ddf0daa","metadata":{"id":"eaac1f6f-c823-4488-8edb-2f931ddf0daa"},"outputs":[],"source":["eval_dic = {i:wrapper_generate(model=base_model, input_prompt=prompt_template.format(System=default_system_msg, User=evaluation_queries[i]))for i, query in enumerate(evaluation_queries)}"]},{"cell_type":"code","execution_count":null,"id":"fefd04ba-2ed8-4f84-bdd0-86d52b3f39f6","metadata":{"id":"fefd04ba-2ed8-4f84-bdd0-86d52b3f39f6"},"outputs":[],"source":["print(eval_dic[0])"]},{"cell_type":"markdown","id":"3f471e3a-723b-4df5-aa72-46f571f6bab6","metadata":{"id":"3f471e3a-723b-4df5-aa72-46f571f6bab6"},"source":["# 미세튜닝된 모델 로딩 후 테스트"]},{"cell_type":"code","execution_count":null,"id":"a43bdd07-7555-42b2-9888-a614afec892f","metadata":{"id":"a43bdd07-7555-42b2-9888-a614afec892f"},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n",")"]},{"cell_type":"code","execution_count":null,"id":"39db2ee4-23c8-471f-89b2-bca34964bf81","metadata":{"id":"39db2ee4-23c8-471f-89b2-bca34964bf81"},"outputs":[],"source":["trained_model = AutoPeftModelForCausalLM.from_pretrained(\n","    script_args.training_args.output_dir,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    cache_dir=script_args.cache_dir\n",")"]},{"cell_type":"code","execution_count":null,"id":"b0b75ca4-730d-4bde-88bb-a86462a76d52","metadata":{"id":"b0b75ca4-730d-4bde-88bb-a86462a76d52"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    script_args.model_name,\n","    trust_remote_code=True,\n","    cache_dir=script_args.cache_dir,\n",")\n","\n","if getattr(tokenizer, \"pad_token\", None) is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n","trained_model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"markdown","source":["추론 과정에서는 GPU 메모리를 약 5.5 GB 활용"],"metadata":{"id":"X1tRCa4EiYXp"},"id":"X1tRCa4EiYXp"},{"cell_type":"code","execution_count":null,"id":"e374555b-9f8a-4617-8ea7-c1e6ee1b2999","metadata":{"id":"e374555b-9f8a-4617-8ea7-c1e6ee1b2999"},"outputs":[],"source":["eval_dic = {i:wrapper_generate(model=trained_model, input_prompt=prompt_template.format(System=default_system_msg, User=evaluation_queries[i]))for i, query in enumerate(evaluation_queries)}"]},{"cell_type":"code","execution_count":null,"id":"5d055bb0-5e5f-4221-a634-45d903c0f3b5","metadata":{"id":"5d055bb0-5e5f-4221-a634-45d903c0f3b5"},"outputs":[],"source":["print(eval_dic[0])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}